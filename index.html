<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Mini Teachable Machine</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.16.0/dist/tf.min.js"></script>
  <style>
    body {
      font-family: 'Poppins', sans-serif;
      background: white;
      text-align: center;
      padding: 20px;
    }
    h1 { color: #333; }
    button, select, input {
      margin: 5px;
      padding: 10px 15px;
      border: none;
      border-radius: 8px;
      background-color: #0078ff;
      color: white;
      cursor: pointer;
      font-size: 14px;
    }
    button:hover { background-color: #005fcc; }
    video, canvas {
      border: 3px solid #ddd;
      border-radius: 10px;
      margin-top: 10px;
      width: 300px;
      height: 220px;
    }
    .class-container {
      border: 2px solid #ddd;
      border-radius: 12px;
      padding: 10px;
      margin: 10px auto;
      width: 320px;
      background: #f9f9f9;
    }
  </style>
</head>
<body>
  <h1>Mini Teachable Machine ðŸš¦</h1>

  <div>
    <label>Device Type:</label>
    <select id="deviceSelect">
      <option value="computer">Computer</option>
      <option value="phone">Phone</option>
    </select>
    <button onclick="startCamera()">Start Camera</button>
  </div>

  <div>
    <label for="cameraSelect">Choose Camera:</label>
    <select id="cameraSelect"></select>
  </div>

  <video id="webcam" autoplay playsinline></video>

  <h2>Training Classes</h2>
  <input type="text" id="classNameInput" placeholder="Enter Class Name" />
  <button onclick="addClass()">Add Class</button>

  <div id="classList"></div>
  <button onclick="trainModel()">Train Model</button>

  <h2>Test Model with Webcam</h2>
  <button onclick="startTesting()">Start Testing</button>
  <p id="prediction">Prediction: None</p>

  <script>
    let video = document.getElementById("webcam");
    let cameraSelect = document.getElementById("cameraSelect");
    let classList = document.getElementById("classList");
    let classes = [];
    let trainingData = {};
    let model;
    let stream;

    async function startCamera() {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const videoDevices = devices.filter(d => d.kind === "videoinput");
      cameraSelect.innerHTML = "";
      videoDevices.forEach((d, i) => {
        const option = document.createElement("option");
        option.value = d.deviceId;
        option.text = d.label || `Camera ${i+1}`;
        cameraSelect.appendChild(option);
      });
      setCamera(videoDevices[0].deviceId);
    }

    async function setCamera(deviceId) {
      if (stream) stream.getTracks().forEach(t => t.stop());
      stream = await navigator.mediaDevices.getUserMedia({
        video: { deviceId: { exact: deviceId } }
      });
      video.srcObject = stream;
    }

    cameraSelect.addEventListener("change", () => {
      setCamera(cameraSelect.value);
    });

    function addClass() {
      const name = document.getElementById("classNameInput").value.trim();
      if (!name) return alert("Enter class name!");
      if (classes.includes(name)) return alert("Class already exists!");
      classes.push(name);
      trainingData[name] = [];
      const div = document.createElement("div");
      div.className = "class-container";
      div.innerHTML = `
        <h3>${name}</h3>
        <button onclick="captureImage('${name}')">ðŸ“¸ Capture</button>
        <p id="${name}-count">Images: 0</p>
      `;
      classList.appendChild(div);
      document.getElementById("classNameInput").value = "";
    }

    function captureImage(className) {
      const canvas = document.createElement("canvas");
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext("2d");
      ctx.drawImage(video, 0, 0);
      const imageData = tf.browser.fromPixels(canvas).resizeNearestNeighbor([64, 64]).toFloat().div(255).expandDims();
      trainingData[className].push(imageData);
      document.getElementById(`${className}-count`).innerText = `Images: ${trainingData[className].length}`;
    }

    async function trainModel() {
      const labels = [];
      const xs = [];
      let index = 0;
      const classIndices = {};
      classes.forEach((cls, i) => (classIndices[cls] = i));
      for (let cls of classes) {
        for (let img of trainingData[cls]) {
          xs.push(img);
          labels.push(classIndices[cls]);
        }
      }
      const xsTensor = tf.concat(xs);
      const ysTensor = tf.tensor1d(labels, "int32");
      const ysOneHot = tf.oneHot(ysTensor, classes.length);
      model = tf.sequential();
      model.add(tf.layers.flatten({ inputShape: [64, 64, 3] }));
      model.add(tf.layers.dense({ units: 64, activation: "relu" }));
      model.add(tf.layers.dense({ units: classes.length, activation: "softmax" }));
      model.compile({ optimizer: "adam", loss: "categoricalCrossentropy", metrics: ["accuracy"] });
      await model.fit(xsTensor, ysOneHot, { epochs: 15 });
      alert("Training complete!");
    }

    async function startTesting() {
      if (!model) return alert("Train the model first!");
      setInterval(() => {
        const canvas = document.createElement("canvas");
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        const ctx = canvas.getContext("2d");
        ctx.drawImage(video, 0, 0);
        const img = tf.browser.fromPixels(canvas).resizeNearestNeighbor([64, 64]).toFloat().div(255).expandDims();
        const prediction = model.predict(img);
        const classIndex = prediction.argMax(-1).dataSync()[0];
        document.getElementById("prediction").innerText = "Prediction: " + classes[classIndex];
      }, 500);
    }
  </script>
</body>
</html>
