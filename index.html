<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Grade 7 ML Science Fair</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.18.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"></script>

<style>
body{margin:0;font-family:Arial;background:#0f0f0f;color:white}
#sidebar{position:fixed;left:0;top:0;width:280px;height:100vh;background:#1a1a1a;padding:20px;border-right:2px solid #333;overflow-y:auto}
#main{margin-left:310px;padding:20px}
h1,h2{margin-bottom:6px}
.btn{width:100%;padding:10px;margin-top:6px;border:none;border-radius:6px;background:#3a3a3a;color:white;cursor:pointer}
.btn:hover{background:#555}
.class-box{background:#222;border:1px solid #555;padding:12px;border-radius:6px;margin-top:10px}
.small{font-size:13px;color:#ccc}
video,img{width:340px;height:260px;border-radius:8px;background:black;object-fit:cover}
.bar-bg{width:100%;height:20px;background:#333;border-radius:6px;margin-top:4px}
.bar-fill{height:100%;width:0%;border-radius:6px;transition:width .2s}
.green{background:#00d26a}
.yellow{background:#f5c542}
.red{background:#ff4d4d}
#accuracyMeter{margin-top:10px;font-size:16px}
</style>
</head>

<body>
<div id="sidebar">
<h2>ðŸ“¦ Classes</h2>
<button class="btn" onclick="addClass()">âž• Add Class</button>
<div id="classList"></div>

<h2 style="margin-top:20px">ðŸ§ª Mode</h2>
<button class="btn" onclick="setMode('live')">ðŸ”´ Live Camera</button>
<button class="btn" onclick="setMode('image')">ðŸ–¼ Image Test</button>

<h2 style="margin-top:20px">ðŸš€ Train</h2>
<button class="btn" id="trainBtn" onclick="trainModel()">Train Model</button>
<p id="trainStatus" class="small"></p>

<h2 style="margin-top:20px">ðŸ“¤ Image</h2>
<input type="file" accept="image/*" onchange="predictImage(this)" class="btn">
</div>

<div id="main">
<h1>Machine Learning Image Classifier</h1>
<p class="small">Uses MobileNet + Transfer Learning</p>

<video id="video" autoplay playsinline></video>
<img id="testImage" style="display:none">

<h2>Predictions</h2>
<div id="predictionArea"></div>

<div id="accuracyMeter">Accuracy: --%</div>

<h2>How It Works (Judges)</h2>
<ul class="small">
<li>Camera or image gives input</li>
<li>MobileNet turns image into numbers</li>
<li>Model learns patterns</li>
<li>Bars show confidence</li>
</ul>
</div>

<script>
let classes=[], net, model, stream=null, mode="live", accuracy=0

async function startCamera(){
 try{
  stream=await navigator.mediaDevices.getUserMedia({video:true})
  video.srcObject=stream
 }catch(e){alert("Camera blocked")}
}

function stopCamera(){
 if(stream){stream.getTracks().forEach(t=>t.stop());stream=null}
}

function setMode(m){
 mode=m
 if(m==="live"){testImage.style.display="none";video.style.display="block";startCamera();loop()}
 else{stopCamera();video.style.display="none"}
}

function addClass(){
 let id=classes.length
 let box=document.createElement("div")
 box.className="class-box"
 box.innerHTML=`
 <input placeholder="Class name" id="name${id}" class="btn">
 <input type="file" accept="image/*" multiple class="btn" onchange="addImages(${id},this)">
 <p id="count${id}" class="small">Images: 0</p>`
 classList.appendChild(box)
 classes.push({images:[],name:""})
}

function addImages(id,input){
 for(let f of input.files){
  let img=new Image()
  img.src=URL.createObjectURL(f)
  classes[id].images.push(img)
 }
 count${id}.textContent="Images: "+classes[id].images.length
}

async function trainModel(){
 if(classes.length<2){alert("Need 2+ classes");return}
 trainBtn.disabled=true
 trainStatus.textContent="Loading model..."
 net=await mobilenet.load()
 let xs=[], ys=[]
 for(let i=0;i<classes.length;i++){
  classes[i].name=document.getElementById("name"+i).value||"Class "+i
  for(let img of classes[i].images){
   let t=tf.browser.fromPixels(img).resizeNearestNeighbor([224,224]).toFloat().div(255).expandDims()
   let e=net.infer(t,"conv_preds")
   xs.push(e); ys.push(i)
   t.dispose()
  }
 }
 let X=tf.concat(xs), Y=tf.tensor1d(ys,"int32")
 model=tf.sequential()
 model.add(tf.layers.dense({inputShape:[1024],units:classes.length,activation:"softmax"}))
 model.compile({optimizer:"adam",loss:"sparseCategoricalCrossentropy",metrics:["accuracy"]})
 trainStatus.textContent="Training..."
 await model.fit(X,Y,{epochs:10,callbacks:{
  onEpochEnd:(e,l)=>{
   accuracy=(l.acc*100).toFixed(1)
   accuracyMeter.textContent="Accuracy: "+accuracy+"%"
  }
 }})
 xs.forEach(t=>t.dispose());X.dispose();Y.dispose()
 trainStatus.textContent="âœ… Training complete"
 trainBtn.disabled=false
 setupBars()
 loop()
}

function setupBars(){
 predictionArea.innerHTML=""
 classes.forEach((c,i)=>{
  predictionArea.innerHTML+=`
  <strong>${c.name}</strong>
  <div class="bar-bg"><div id="bar${i}" class="bar-fill"></div></div>
  <span id="pct${i}" class="small"></span>`
 })
}

async function predict(tensor){
 let e=net.infer(tensor,"conv_preds")
 let p=model.predict(e)
 let data=await p.data()
 data.forEach((v,i)=>{
  let percent=(v*100).toFixed(1)
  let bar=document.getElementById("bar"+i)
  bar.style.width=percent+"%"
  bar.className="bar-fill "+(percent>70?"green":percent>40?"yellow":"red")
  pct${i}.textContent=percent+"%"
 })
 tensor.dispose();e.dispose();p.dispose()
}

async function loop(){
 if(!model||mode!=="live")return
 let t=tf.browser.fromPixels(video).resizeNearestNeighbor([224,224]).toFloat().div(255).expandDims()
 await predict(t)
 requestAnimationFrame(loop)
}

async function predictImage(input){
 if(!model)return
 let img=testImage
 img.src=URL.createObjectURL(input.files[0])
 img.style.display="block"
 await img.decode()
 let t=tf.browser.fromPixels(img).resizeNearestNeighbor([224,224]).toFloat().div(255).expandDims()
 await predict(t)
}

startCamera()
</script>
</body>
</html>
